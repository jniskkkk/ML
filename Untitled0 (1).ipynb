{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eniUj-f9Tk47",
        "outputId": "f2cf208d-3201-4d50-f50a-26db1e430700"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        " !pip install  pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from multiprocessing import Pool\n",
        "import time\n",
        "import warnings\n",
        "\n",
        "# PySpark libraries\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.regression import RandomForestRegressor as SparkRF\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "np.random.seed(42)\n",
        "data = pd.DataFrame({\n",
        "    'temperature': np.random.normal(30, 5, 100000),\n",
        "    'humidity': np.random.uniform(20, 90, 100000),\n",
        "    'wind_speed': np.random.gamma(2, 3, 100000),\n",
        "    'vegetation_index': np.random.beta(2, 5, 100000),\n",
        "    'burn_area': np.random.exponential(10, 100000)\n",
        "})\n",
        "\n",
        "\n",
        "# 2. Parallel Preprocessing Function\n",
        "def process_column(df, col):\n",
        "    if pd.api.types.is_numeric_dtype(df[col]):\n",
        "        return pd.Series((df[col] - df[col].mean()) / df[col].std(), name=col)\n",
        "    return df[col]\n",
        "\n",
        "def parallel_preprocess(df):\n",
        "    # Create a list of arguments for process_column (df and column name)\n",
        "    args = [(df, col) for col in df.columns]\n",
        "    with Pool(4) as pool:\n",
        "        processed = pool.starmap(process_column, args)\n",
        "    return pd.concat(processed, axis=1)\n",
        "\n",
        "\n",
        "# 3. Preprocessing: Parallel vs Serial Timing\n",
        "\n",
        "# Parallel\n",
        "start = time.time()\n",
        "data_parallel = parallel_preprocess(data)\n",
        "parallel_time = time.time() - start\n",
        "\n",
        "# Serial\n",
        "start = time.time()\n",
        "data_serial = data.copy()\n",
        "for col in data.columns:\n",
        "    if pd.api.types.is_numeric_dtype(data[col]):\n",
        "        data_serial[col] = (data[col] - data[col].mean()) / data[col].std()\n",
        "serial_time = time.time() - start\n",
        "\n",
        "print(f\"âœ… Parallel preprocessing time: {parallel_time:.2f}s\")\n",
        "print(f\"âœ… Serial preprocessing time: {serial_time:.2f}s\")\n",
        "\n",
        "\n",
        "X = data_parallel.drop('burn_area', axis=1)\n",
        "y = data_parallel['burn_area']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "lr = LinearRegression().fit(X_train, y_train)\n",
        "lr_time = time.time() - start\n",
        "lr_rmse = np.sqrt(mean_squared_error(y_test, lr.predict(X_test)))\n",
        "\n",
        "# -------------------------------------------\n",
        "start = time.time()\n",
        "rf_serial = RandomForestRegressor(n_estimators=100, n_jobs=1).fit(X_train, y_train)\n",
        "rf_serial_time = time.time() - start\n",
        "rf_serial_rmse = np.sqrt(mean_squared_error(y_test, rf_serial.predict(X_test)))\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "rf_parallel = RandomForestRegressor(n_estimators=100, n_jobs=-1).fit(X_train, y_train)\n",
        "rf_parallel_time = time.time() - start\n",
        "rf_parallel_rmse = np.sqrt(mean_squared_error(y_test, rf_parallel.predict(X_test)))\n",
        "\n",
        "\n",
        "\n",
        "spark = SparkSession.builder.appName(\"WildfirePrediction\").getOrCreate()\n",
        "spark_df = spark.createDataFrame(data_parallel)\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=[c for c in data_parallel.columns if c != 'burn_area'],\n",
        "    outputCol=\"features\"\n",
        ")\n",
        "spark_df = assembler.transform(spark_df).select(\"features\", \"burn_area\")\n",
        "train, test = spark_df.randomSplit([0.8, 0.2])\n",
        "\n",
        "start = time.time()\n",
        "spark_rf = SparkRF(featuresCol=\"features\", labelCol=\"burn_area\", numTrees=100)\n",
        "spark_model = spark_rf.fit(train)\n",
        "spark_time = time.time() - start\n",
        "\n",
        "spark_preds = spark_model.transform(test)\n",
        "spark_rmse = spark_preds.selectExpr(\"sqrt(avg((burn_area - prediction)*(burn_area - prediction))) as rmse\").collect()[0]['rmse']\n",
        "\n",
        "\n",
        "results = pd.DataFrame({\n",
        "    'Approach': ['Linear Regression', 'RF (Serial)', 'RF (Parallel)', 'Spark RF'],\n",
        "    'Training Time (s)': [lr_time, rf_serial_time, rf_parallel_time, spark_time],\n",
        "    'RMSE': [lr_rmse, rf_serial_rmse, rf_parallel_rmse, spark_rmse],\n",
        "    'Speedup': ['-',\n",
        "                '-',\n",
        "                f\"{rf_serial_time/rf_parallel_time:.1f}x\",\n",
        "                f\"{rf_serial_time/spark_time:.1f}x\"]\n",
        "})\n",
        "\n",
        "print(\"\\nðŸ“Š === Model Training Results ===\")\n",
        "print(results.to_markdown(index=False))\n",
        "\n",
        "\n",
        "\n",
        "spark.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qm8ZGqFyVNAF",
        "outputId": "fbcb7121-cc60-4f4a-cf44-a7d7c55944ea"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Parallel preprocessing time: 0.18s\n",
            "âœ… Serial preprocessing time: 0.02s\n",
            "\n",
            "ðŸ“Š === Model Training Results ===\n",
            "| Approach          |   Training Time (s) |     RMSE | Speedup   |\n",
            "|:------------------|--------------------:|---------:|:----------|\n",
            "| Linear Regression |           0.0374215 | 0.995494 | -         |\n",
            "| RF (Serial)       |         158.574     | 1.01995  | -         |\n",
            "| RF (Parallel)     |         131.571     | 1.01971  | 1.2x      |\n",
            "| Spark RF          |          40.2768    | 0.998765 | 3.9x      |\n"
          ]
        }
      ]
    }
  ]
}